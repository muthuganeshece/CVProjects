{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c34ee55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da1fbfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6fd6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Directory = r\"F:\\Work\\SOCAAutomation\\Dataset\\Images\\09072024_1_1\"\n",
    "FileName = \"2024_07_09_11_30_174.jpg\"\n",
    "raw_img = cv.imread(Directory + \"/\" + FileName)\n",
    "img = cv.cvtColor(raw_img, cv.COLOR_BGR2GRAY)\n",
    "img = raw_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e80b5a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO('best.pt', task='segment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b2e92c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = YOLO('best.pt')\n",
    "results = model(img, conf=0.3, save=True, show_labels=False, retina_masks=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ca2a15",
   "metadata": {},
   "source": [
    "**Pre and Post processing time**\n",
    "- reduced from 5 seconds to ms by resizing the image before applying to the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6840a7a3",
   "metadata": {},
   "source": [
    "# Video Inferencing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d92b528",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics.utils.plotting import Annotator, colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8e0bfb3f",
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.10.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\resize.cpp:4152: error: (-215:Assertion failed) !ssize.empty() in function 'cv::resize'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[52], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m img_resize \u001b[38;5;241m=\u001b[39m cv\u001b[38;5;241m.\u001b[39mresize(frame, (width, height), interpolation \u001b[38;5;241m=\u001b[39m cv\u001b[38;5;241m.\u001b[39mINTER_LINEAR)\n\u001b[0;32m      2\u001b[0m results \u001b[38;5;241m=\u001b[39m model(img_resize, conf\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m results[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmasks \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.10.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\resize.cpp:4152: error: (-215:Assertion failed) !ssize.empty() in function 'cv::resize'\n"
     ]
    }
   ],
   "source": [
    "img_resize = cv.resize(frame, (width, height), interpolation = cv.INTER_LINEAR)\n",
    "results = model(img_resize, conf=0.5)\n",
    "if results[0].masks is not None:\n",
    "    mask_img = np.any(np.array(results[0].masks[:].data), axis=0)\n",
    "    mask_img_3 = np.stack([mask_img, np.zeros(mask_img.shape), np.zeros(mask_img.shape)], axis=2)\n",
    "    temp_image = cv.addWeighted(img_resize, alpha , (mask_img_3 * 255).astype('uint8'), 1-alpha, 0)        \n",
    "    im_out = cv.warpPerspective(mask_img_3, h, (im_layout.shape[1],im_layout.shape[0]))\n",
    "    layout_mask = cv.addWeighted(im_layout, 0.3 , (im_out * 255).astype('uint8'), 1-0.3, 0)\n",
    "layout_mask = cv.addWeighted(im_layout, 0.3 , (im_out * 255).astype('uint8'), 1-0.3, 0)\n",
    "im_show(layout_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b6142f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def im_show(img):\n",
    "    cv.imshow('1', img)\n",
    "    cv.waitKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a702b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Camera Perspective View to Top View Transformation\n",
    "def camera_angle2top_view():\n",
    "    points = pd.read_csv('Points.csv')\n",
    "    ref_pts = np.array([points.iloc[i,:2] for i in range(1, len(points))], dtype = 'uint16')\n",
    "    dst_pts = np.array([points.iloc[i,2:] for i in range(1, len(points))], dtype = 'uint16') * 2\n",
    "    h, status = cv.findHomography(ref_pts, dst_pts)\n",
    "    return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ca2ac987",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def InferenceImage(frame, model, width, height, alpha, im_layout, h):\n",
    "#     img_resize = cv.resize(frame, (width, height), interpolation = cv.INTER_LINEAR)\n",
    "#     results = model(img_resize, conf=0.5)\n",
    "#     if results[0].masks is not None:\n",
    "#         mask_img = np.any(np.array(results[0].masks[:].data), axis=0)\n",
    "#         mask_img_3 = np.stack([mask_img, np.zeros(mask_img.shape), np.zeros(mask_img.shape)], axis=2)\n",
    "#         temp_image = cv.addWeighted(img_resize, alpha , (mask_img_3 * 255).astype('uint8'), 1-alpha, 0)        \n",
    "#         im_out = cv.warpPerspective(mask_img_3, h, (im_layout.shape[1],im_layout.shape[0]))\n",
    "#         layout_mask = cv.addWeighted(im_layout, 0.3 , (im_out * 255).astype('uint8'), 1-0.3, 0)\n",
    "# #         mask_inv = np.logical_not(np.stack([mask_img, mask_img, mask_img], axis=2))\n",
    "# #         temp_image = np.zeros(orig_img.shape)\n",
    "# #         temp_image = mask_inv * orig_img\n",
    "# #         temp_image += (mask_img_3 * 255).astype('uint8')\n",
    "#     else:\n",
    "#         temp_image = img_resize\n",
    "#         layout_mask = im_layout\n",
    "#     return temp_image, layout_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "1320fb43",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_frame = 0\n",
    "fps = 1\n",
    "alpha = 0.8\n",
    "Directory = r\"F:\\Work\\SOCAAutomation\\Dataset\\Images\\09072024_1_1\"\n",
    "\n",
    "width = height = 640\n",
    "Files = os.listdir(Directory)\n",
    "Files = ['2024_07_09_11_30_114.jpg', '2024_07_09_11_30_115.jpg', '2024_07_09_11_30_116.jpg', '2024_07_09_11_30_117.jpg', '2024_07_09_11_30_118.jpg']\n",
    "im_ref = cv.imread('ReferenceImage.jpg')\n",
    "#im_layout = cv.imread('Layout.jpg')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "456de97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO('best.pt')\n",
    "out = cv.VideoWriter(\"inst_segment.avi\", cv.VideoWriter_fourcc(*\"MJPG\"), fps, (width, height))\n",
    "out2 = cv.VideoWriter(\"inst_seg_layout.avi\", cv.VideoWriter_fourcc(*\"MJPG\"), fps, (im_layout.shape[1], im_layout.shape[0]))\n",
    "video = cv.VideoCapture(r\"F:\\Work\\SOCAAutomation\\Dataset\\NA_DISOPSAL_SOCA_2024\\09072024\\AXIS 213 - 10.1.5.173 2024-07-09_11_30_00_000.asf\")\n",
    "dur = [[3,0], [3,45]] #[mins,secs]\n",
    "startFrame = (dur[0][0] * 60 + dur[0][1] ) * 15\n",
    "endFrame = (dur[1][0] * 60 + dur[1][1] ) * 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "81c67aa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 4 Fire-Smoke-Sodium-Trays, 4071.7ms\n",
      "Speed: 14.0ms preprocess, 4071.7ms inference, 16.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 Fire-Smoke-Sodium-Trays, 4060.7ms\n",
      "Speed: 7.0ms preprocess, 4060.7ms inference, 12.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 4 Fire-Smoke-Sodium-Trays, 4351.9ms\n",
      "Speed: 7.0ms preprocess, 4351.9ms inference, 25.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 4 Fire-Smoke-Sodium-Trays, 4253.8ms\n",
      "Speed: 7.0ms preprocess, 4253.8ms inference, 17.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    }
   ],
   "source": [
    "count_frame = 0\n",
    "h = camera_angle2top_view()\n",
    "while True:\n",
    "    ret, frame = video.read()\n",
    "    if ret:\n",
    "        if count_frame >= 0 and count_frame < 4:\n",
    "            frame = cv.imread(Directory + \"/\" + Files[count_frame])\n",
    "            img_resize = cv.resize(frame, (width, height), interpolation = cv.INTER_LINEAR)\n",
    "            results = model(img_resize, conf=0.5)\n",
    "            if results[0].masks is not None:\n",
    "                mask_img = np.any(np.array(results[0].masks[:].data), axis=0)\n",
    "                mask_img_3 = np.stack([np.zeros(mask_img.shape), np.zeros(mask_img.shape), mask_img], axis=2)\n",
    "                temp_image = cv.addWeighted(img_resize, alpha , (mask_img_3 * 255).astype('uint8'), 1-alpha, 0)        \n",
    "                im_out = cv.warpPerspective(mask_img_3, h, (im_layout.shape[1],im_layout.shape[0]))\n",
    "                layout_mask = cv.addWeighted(im_layout, 0.3 , (im_out * 255).astype('uint8'), 1-0.3, 0)\n",
    "            else:\n",
    "                temp_image = img_resize\n",
    "                layout_mask = im_layout\n",
    "                \n",
    "            out.write(temp_image)\n",
    "            out2.write(layout_mask)\n",
    "            count_frame += 1\n",
    "    else:\n",
    "        break\n",
    "out.release()\n",
    "out2.release()\n",
    "video.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "816a2bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_img_3 = np.stack([np.zeros(mask_img.shape), np.zeros(mask_img.shape), mask_img], axis=2)\n",
    "temp_image = cv.addWeighted(img_resize, alpha , (mask_img_3 * 255).astype('uint8'), 1-alpha, 0)        \n",
    "im_out = cv.warpPerspective(mask_img_3, h, (im_layout.shape[1],im_layout.shape[0]))\n",
    "layout_mask = cv.addWeighted(im_layout, 0.3 , (im_out * 255).astype('uint8'), 1-0.3, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1f4fc322",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = np.zeros((640,640,3))\n",
    "test= layout_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "3fbc2b80",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with remapped shapes [original->remapped]: (3,)  and requested shape (3,2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[76], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m pad_arr \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mpad(layout_mask, (\u001b[38;5;241m640\u001b[39m\u001b[38;5;241m-\u001b[39mlayout_mask\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m],\u001b[38;5;241m640\u001b[39m\u001b[38;5;241m-\u001b[39mlayout_mask\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], \u001b[38;5;241m3\u001b[39m), \u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mpad\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\numpy\\lib\\arraypad.py:744\u001b[0m, in \u001b[0;36mpad\u001b[1;34m(array, pad_width, mode, **kwargs)\u001b[0m\n\u001b[0;32m    741\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m`pad_width` must be of integral type.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    743\u001b[0m \u001b[38;5;66;03m# Broadcast to shape (array.ndim, 2)\u001b[39;00m\n\u001b[1;32m--> 744\u001b[0m pad_width \u001b[38;5;241m=\u001b[39m _as_pairs(pad_width, array\u001b[38;5;241m.\u001b[39mndim, as_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    746\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(mode):\n\u001b[0;32m    747\u001b[0m     \u001b[38;5;66;03m# Old behavior: Use user-supplied function with np.apply_along_axis\u001b[39;00m\n\u001b[0;32m    748\u001b[0m     function \u001b[38;5;241m=\u001b[39m mode\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\numpy\\lib\\arraypad.py:518\u001b[0m, in \u001b[0;36m_as_pairs\u001b[1;34m(x, ndim, as_index)\u001b[0m\n\u001b[0;32m    514\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex can\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt contain negative values\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    516\u001b[0m \u001b[38;5;66;03m# Converting the array with `tolist` seems to improve performance\u001b[39;00m\n\u001b[0;32m    517\u001b[0m \u001b[38;5;66;03m# when iterating and indexing the result (see usage in `pad`)\u001b[39;00m\n\u001b[1;32m--> 518\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mbroadcast_to(x, (ndim, \u001b[38;5;241m2\u001b[39m))\u001b[38;5;241m.\u001b[39mtolist()\n",
      "File \u001b[1;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mbroadcast_to\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\numpy\\lib\\stride_tricks.py:413\u001b[0m, in \u001b[0;36mbroadcast_to\u001b[1;34m(array, shape, subok)\u001b[0m\n\u001b[0;32m    367\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_broadcast_to_dispatcher, module\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumpy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    368\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbroadcast_to\u001b[39m(array, shape, subok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m    369\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Broadcast an array to a new shape.\u001b[39;00m\n\u001b[0;32m    370\u001b[0m \n\u001b[0;32m    371\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    411\u001b[0m \u001b[38;5;124;03m           [1, 2, 3]])\u001b[39;00m\n\u001b[0;32m    412\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 413\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _broadcast_to(array, shape, subok\u001b[38;5;241m=\u001b[39msubok, readonly\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\numpy\\lib\\stride_tricks.py:349\u001b[0m, in \u001b[0;36m_broadcast_to\u001b[1;34m(array, shape, subok, readonly)\u001b[0m\n\u001b[0;32m    346\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mall elements of broadcast shape must be non-\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    347\u001b[0m                      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnegative\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    348\u001b[0m extras \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m--> 349\u001b[0m it \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mnditer(\n\u001b[0;32m    350\u001b[0m     (array,), flags\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmulti_index\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrefs_ok\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzerosize_ok\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m extras,\n\u001b[0;32m    351\u001b[0m     op_flags\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreadonly\u001b[39m\u001b[38;5;124m'\u001b[39m], itershape\u001b[38;5;241m=\u001b[39mshape, order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    352\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m it:\n\u001b[0;32m    353\u001b[0m     \u001b[38;5;66;03m# never really has writebackifcopy semantics\u001b[39;00m\n\u001b[0;32m    354\u001b[0m     broadcast \u001b[38;5;241m=\u001b[39m it\u001b[38;5;241m.\u001b[39mitviews[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with remapped shapes [original->remapped]: (3,)  and requested shape (3,2)"
     ]
    }
   ],
   "source": [
    "pad_arr = np.pad(layout_mask, (640-layout_mask.shape[0],640-layout_mask.shape[1], 3), 0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "c081572e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(578, 478, 3)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layout_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "0d8210f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "im_show(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b05d7a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "out.release()\n",
    "video.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5f4689",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.imshow('window', temp_image)\n",
    "cv.waitKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebcf5dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.8\n",
    "dst = cv.addWeighted(im1, alpha , im2, 1-alpha, 0) \n",
    "plt.imshow(im2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201a0c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.6\n",
    "im1 = cv.imread(r'F:\\Work\\SOCAAutomation\\Dataset\\Images\\09072024_1_1\\2024_07_09_11_30_32.jpg')\n",
    "im1 = cv.resize(im1, (640, 640), interpolation = cv.INTER_LINEAR)\n",
    "#results = model(im1, conf=0.5) #, save=True, show_labels=False, retina_masks=True)\n",
    "mask_img = np.any(np.array(results[0].masks[:].data), axis=0)\n",
    "orig_img = im1 #results[0].orig_img\n",
    "mask_img_3 = np.stack([mask_img, np.zeros(mask_img.shape), np.zeros(mask_img.shape)], axis=2)\n",
    "\n",
    "im2 = np.array(mask_img_3 * 255, dtype = 'uint8')\n",
    "\n",
    "dst = cv.addWeighted(im1, alpha , im2, 1-alpha, 0) \n",
    "# mask_inv = np.logical_not(np.stack([mask_img, mask_img, mask_img], axis=2))\n",
    "# temp_image = np.zeros(orig_img.shape)\n",
    "# temp_image = mask_inv * orig_img\n",
    "# temp_image += (mask_img_3 * 255).astype('uint8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db70c103",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(mask_img_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8d6606",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80410674",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = cv.imread(r'F:\\Work\\SOCAAutomation\\Dataset\\Images\\09072024_1_1\\2024_07_09_11_30_344.jpg')\n",
    "img_resize = cv.resize(frame, (640, 640), interpolation = cv.INTER_LINEAR)\n",
    "cv.imwrite('ReferenceImage.jpg', img_resize)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f5f6f4",
   "metadata": {},
   "source": [
    "# Transform Model to Onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7433d2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.export(format=\"onnx\")  # creates 'yolov8n_openvino_model/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ef66c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_model = YOLO(\"best.onnx\", task='segment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7b2bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_onnx = onnx_model(img, conf=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdeabf53",
   "metadata": {},
   "source": [
    "## ONNX Model Optimizations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2087e25",
   "metadata": {},
   "source": [
    "### F32 to F16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e75a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "from onnxconverter_common import float16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8660317",
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_model = onnx.load(\"best.onnx\")\n",
    "onnx_model_fp16 = float16.convert_float_to_float16(onnx_model)\n",
    "onnx.save(onnx_model_fp16, \"model_fp16.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6b40c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_model = YOLO(\"model_fp16.onnx\", task='segment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a994e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_onnx_fp16 = onnx_model(img, conf=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb81822",
   "metadata": {},
   "outputs": [],
   "source": [
    "img.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b97da74",
   "metadata": {},
   "source": [
    "# Transform Model to OpenVino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dbecb79",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.export(format=\"openvino\")  # creates 'yolov8n_openvino_model/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956891a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ov_model = YOLO(\"yolov8n_openvino_model/\")\n",
    "\n",
    "# Run inference\n",
    "results = ov_model(\"https://ultralytics.com/images/bus.jpg\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
